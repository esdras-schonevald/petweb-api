# This workflow will build and push a new container image to Amazon ECR,
# and then will deploy a new task definition to Amazon ECS, when there is a push to the "dev" branch.
#
# To use this workflow, you will need to complete the following set-up steps:
#
# 1. Create an ECR repository to store your images.
#    For example: `aws ecr create-repository --repository-name my-ecr-repo --region us-east-2`.
#    Replace the value of the `ECR_REPOSITORY` environment variable in the workflow below with your repository's name.
#    Replace the value of the `AWS_REGION` environment variable in the workflow below with your repository's region.
#
# 2. Create an ECS task definition, an ECS cluster, and an ECS service.
#    For example, follow the Getting Started guide on the ECS console:
#      https://us-east-2.console.aws.amazon.com/ecs/home?region=us-east-2#/firstRun
#    Replace the value of the `ECS_SERVICE` environment variable in the workflow below with the name you set for the Amazon ECS service.
#    Replace the value of the `ECS_CLUSTER` environment variable in the workflow below with the name you set for the cluster.
#
# 3. Store your ECS task definition as a JSON file in your repository.
#    The format should follow the output of `aws ecs register-task-definition --generate-cli-skeleton`.
#    Replace the value of the `ECS_TASK_DEFINITION` environment variable in the workflow below with the path to the JSON file.
#    Replace the value of the `CONTAINER_NAME` environment variable in the workflow below with the name of the container
#    in the `containerDefinitions` section of the task definition.
#
# 4. Store an IAM user access key in GitHub Actions secrets named `AWS_ACCESS_KEY_ID` and `AWS_SECRET_ACCESS_KEY`.
#    See the documentation for each action used below for the recommended IAM policies for this IAM user,
#    and best practices on handling the access key credentials.

name: Deploy to Amazon ECS

on:
  push:
    branches: [ "master" ]

jobs:
  deploy:
    name: Deploy
    runs-on: ubuntu-latest
    environment: production

    steps:
    - name: Checkout
      uses: actions/checkout@v3

    - name: Down
      run: docker-compose down -f /var/www/petweb/docker-compose.yml
      
    - name: Use Su
      run: sudo su
      
    - name: Copy
      uses: easingthemes/ssh-deploy@main
      env:
        ARGS: "-rltgoDzvO --delete"
        SSH_PRIVATE_KEY: ${{ secrets.EC2_SSH_KEY }}
        SOURCE: .
        REMOTE_HOST: ec2-3-144-212-85.us-east-2.compute.amazonaws.com
        REMOTE_USER: ec2-user
        TARGET: /var/www/petweb
    
    - name: Cache
      uses: actions/cache@v3.0.11
      with:
        ## A list of files, directories, and wildcard patterns to cache and restore
        path: "/vendor/, .env, /.docker/"
        ## An explicit key for restoring and saving the cache
        key: ${{ runner.os }}-cache
        ## An ordered list of keys to use for restoring stale cache if no cache hit occurred for key. Note `cache-hit` returns false in this case.
        #restore-keys: # optional
        ## The chunk size used to split up large files during upload, in bytes
        #upload-chunk-size: # optional
